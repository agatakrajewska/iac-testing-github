apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-controller
  labels:
    {{- include "slurm.labels" . | nindent 4 }}
spec:
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: slurmctld
      app.kubernetes.io/instance: {{ .Release.Name }}-controller
      app.kubernetes.io/component: "controller"
      {{- include "slurm.labels" . | nindent 6 }}
  replicas: {{ .Values.controller.replicas }} # by default is 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: slurmctld
        app.kubernetes.io/instance: {{ .Release.Name }}-controller
        app.kubernetes.io/component: "controller"
        {{- include "slurm.labels" . | nindent 8 }}
      annotations:
        kubectl.kubernetes.io/default-container: "slurmctld"
        {{- include "slurm.networkAffinities" . | nindent 8 }}
    spec:
      terminationGracePeriodSeconds: {{ .Values.controller.terminationGracePeriodSeconds }}
      {{- include "slurm.dnsConfig" . | nindent 6 }}
      enableServiceLinks: false
      hostname: {{ .Release.Name }}-controller
      initContainers:
      # The initcontainer is needed mostly to persist etc from the image in an emptyDir
      # This way we can modify /etc/passwd and similar via a SSSD sidecar
      - name: init
        image: "{{ .Values.controller.image.repository }}:{{ default (print "v" .Chart.Version ) .Values.controller.image.tag }}"
        command: ["/usr/share/sunk/bin/init.sh"]
        env:
        - name: ROLE
          value: "controller"
        - name: SLURM_USER
          value: "{{ .Values.controller.securityContext.runAsUser }}"
        - name: SLURM_GROUP
          value: "{{ .Values.controller.securityContext.runAsGroup }}"
        volumeMounts:
        {{- if (include "directories" . ) }}
        - name: sssd-pipes
          mountPath: /runtime/var/lib/sss/pipes
        - name: sssd-cache
          mountPath: /var/lib/sss/db
        {{- end }}
        - name: etc
          mountPath: /runtime/etc
        - name: run
          mountPath: /run
        - name: munge
          mountPath: /munge/munge.secret.key
          subPath: munge.key
          readOnly: true
        - name: slurmctld-state
          mountPath: /var/spool/slurmctld
      containers:
      {{- include "slurm.sssdContainer" . | nindent 6 }}
      - name: munged
        {{- include "slurm.mungedContainer" . | nindent 8 }}
      - name: watch
        image: "{{ .Values.controller.image.repository }}:{{ default (print "v" .Chart.Version ) .Values.controller.image.tag }}"
        command:
        - "/usr/share/sunk/bin/reconfigure-watch.sh"
        - "/etc/slurm/slurm.conf"
        - "/etc/slurm/gres.conf"
        {{- range $name, $v := .Values.compute.nodes -}}
        {{- if $v.enabled }}
        - "/etc/slurm/{{ $.Release.Name }}-{{ $name }}-nodes.conf"
        {{- end -}}
        {{- end }}
        resources:
          limits:
            cpu: 250m
            memory: 100Mi
        volumeMounts:
        - name: run
          mountPath: /run
        - name: etc
          mountPath: /etc
        - name: slurm-conf
          mountPath: /etc/slurm
          readOnly: true
        securityContext:
          runAsNonRoot: true
          runAsUser: {{ .Values.controller.securityContext.runAsUser }}
          runAsGroup: {{ .Values.controller.securityContext.runAsGroup }}
      - name: slurmctld
        image: "{{ .Values.controller.image.repository }}:{{ default (print "v" .Chart.Version ) .Values.controller.image.tag }}"
        command: ["slurmctld", "-D"]
        resources:
          {{- toYaml .Values.controller.resources | nindent 10 }}
        ports:
        - containerPort: 6817
          name: slurmctld
        livenessProbe:
          {{- toYaml .Values.controller.livenessProbe | nindent 10 }}
        volumeMounts:
        {{- if (include "directories" . ) }}
        - name: sssd-pipes
          mountPath: /var/lib/sss/pipes
        - name: sssd-cache
          mountPath: /var/lib/sss/db
        {{- end }}
        - name: run
          mountPath: /run
        - name: etc
          mountPath: /etc
        - name: slurmctld-state
          mountPath: /var/spool/slurmctld
        - name: slurm-conf
          mountPath: /etc/slurm
          readOnly: true
        - name: jwt-secret
          mountPath: {{ include "slurm.jwt.path" . }}
          subPath: jwt.key
          readOnly: true
        securityContext:
          runAsNonRoot: true
          runAsUser: {{ .Values.controller.securityContext.runAsUser }}
          runAsGroup: {{ .Values.controller.securityContext.runAsGroup }}
      volumes:
      {{- include "slurm.runtimeVolumes" . | nindent 6 }}
      - name: jwt-secret
        secret:
          secretName: {{ include "slurm.jwt.secretName" . }}
      - name: slurmctld-state
        persistentVolumeClaim:
          claimName: {{ .Release.Name }}-slurmctld-state
      {{- include "slurm.config.volume" . | nindent 6 }}
      automountServiceAccountToken: false
      priorityClassName: {{ .Values.controller.priorityClassName }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/region
                operator: In
                values:
                - {{ .Values.nodeSelector.region }}
              - key: cpu.coreweave.cloud/family
                operator: In
                values:
                  - epyc
      tolerations:
        {{- toYaml .Values.controller.tolerations | nindent 8 }}
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
